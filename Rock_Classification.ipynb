{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzJ2Wx-8ynjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b7eb57-3d2a-4580-962a-8356469aedd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import tarfile\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygXGCRqpzMYC",
        "outputId": "86a82eca-8d8c-4c17-88e6-4a1a9cfd7fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/RockClassification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-atzUYwzrX7",
        "outputId": "ead7a237-752f-417f-934f-27801130b17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/RockClassification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/RockClassification\""
      ],
      "metadata": {
        "id": "p5-PbK_Izwxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d salmaneunus/rock-classification"
      ],
      "metadata": {
        "id": "a3TNbOJNz3e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "VhvXVvhr0A6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with ZipFile(\"rock-classification.zip\", 'r') as zip:\n",
        "#     # printing all the contents of the zip file\n",
        "#     zip.printdir()\n",
        "  \n",
        "#     # extracting all the files\n",
        "#     print('Extracting all the files now...')\n",
        "#     zip.extractall()\n",
        "#     print('Done!')"
      ],
      "metadata": {
        "id": "JvSNydCH3ZrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/RockClassification/Dataset\"\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"/train\")\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "basewidth = 300\n",
        "input_dim = (32, 32)\n",
        "# for cl in classes:\n",
        "#   i=0\n",
        "#   for name in glob.glob(data_dir+\"/train/\"+cl+\"/*\"):\n",
        "#     print(name)\n",
        "#     img = Image.open(name)\n",
        "#     # wpercent = (basewidth / float(img.size[0]))\n",
        "#     # hsize = int((float(img.size[1]) * float(wpercent)))\n",
        "#     img = img.resize(input_dim, Image.ANTIALIAS)\n",
        "#     print(img.size)\n",
        "#     img.convert('RGB').save(name)\n",
        "#     # print(\"Saving Image\")\n",
        "#     i += 1\n",
        "\n",
        "# for cl in classes:\n",
        "#   i=0\n",
        "#   for name in glob.glob(data_dir+\"/test/\"+cl+\"/*\"):\n",
        "#     print(name)\n",
        "#     img = Image.open(name)\n",
        "#     # wpercent = (basewidth / float(img.size[0]))\n",
        "#     # hsize = int((float(img.size[1]) * float(wpercent)))\n",
        "#     img = img.resize(input_dim, Image.ANTIALIAS)\n",
        "#     print(img.size)\n",
        "#     img.convert('RGB').save(name)\n",
        "#     # print(\"Saving Image\")\n",
        "#     i += 1"
      ],
      "metadata": {
        "id": "nkZGBdW35SdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69fc7b1-08a2-4bca-ab90-fa08b10bc8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'train', 'Igneous', 'Metamorphic', 'Sedimentary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
        "                         tt.RandomHorizontalFlip(), \n",
        "                         # tt.RandomRotate\n",
        "                         # tt.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n",
        "                         # tt.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "                         tt.ToTensor(), \n",
        "                         tt.Normalize(*stats,inplace=True)])\n",
        "valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])"
      ],
      "metadata": {
        "id": "b3K4l7XW6phU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ImageFolder(data_dir+'/train', train_tfms)\n",
        "valid_ds = ImageFolder(data_dir+'/test', valid_tfms)"
      ],
      "metadata": {
        "id": "32zBIOVxR29q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "5XQfIyyVWkFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "cIlKEhtBcSCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c5bcb5-005f-4945-ed8c-988ad3ba8ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "metadata": {
        "id": "CoBNeUY9vK_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "iTVpKWZqcSU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(images, means, stds):\n",
        "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
        "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
        "    return images * stds + means\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        denorm_images = denormalize(images, *stats)\n",
        "        ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0,1))\n",
        "        break"
      ],
      "metadata": {
        "id": "8d9d_VIuWoiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size, num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size*2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)"
      ],
      "metadata": {
        "id": "FgqyeqwuFxKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show_batch(train_dl)"
      ],
      "metadata": {
        "id": "W9r9Y5DPWuc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, stride =1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, stride =1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        return self.relu2(out) + x"
      ],
      "metadata": {
        "id": "Xv06JtFyWxDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels))/len(preds)"
      ],
      "metadata": {
        "id": "j421UjU6XAHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images ,  labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        return loss\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        acc = accuracy(out, labels)\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        # batch_accs = torch.FloatTensor(batch_accs)\n",
        "        epoch_acc = torch.stack(batch_accs).mean()\n",
        "        return {'val_loss' : epoch_loss.item(), 'val_acc' : epoch_acc.item()}\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "OGupcFylXEWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool = False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding=1),\n",
        "             nn.BatchNorm2d(out_channels),\n",
        "             nn.ReLU(inplace = True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128,128), conv_block(128,128))\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512,512), conv_block(512,512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                        nn.Flatten(),\n",
        "                                       nn.Dropout(0.2),\n",
        "                                       nn.Linear(512, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        out  = self.res1(out) + out\n",
        "\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "mFOZbD6aXHSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(classes))\n",
        "\n",
        "model = ResNet9(3,len(classes))"
      ],
      "metadata": {
        "id": "to20A8-aXLkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9876ad3-4e8d-43ce-9528-b681a2fc168f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.zeros(1,3,32,32))"
      ],
      "metadata": {
        "id": "Ty4o64th1sw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ecab1a-5e3c-4ad2-d2bd-a5adc526b2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2057,  2.9941,  0.3096, -3.9334,  2.5692,  2.3175, -2.0911]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_device(model,  device)"
      ],
      "metadata": {
        "id": "fhfimLCLXNtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e08239b-1c87-49b1-c531-d6bc04d93de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet9(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res1): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res2): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "AdsMnfOoXPxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in  optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "aWkpEJDbXSr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step\n",
        "            \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "        \n",
        "    return history\n",
        "        "
      ],
      "metadata": {
        "id": "YEog22X0XUxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ],
      "metadata": {
        "id": "UbL6Bx7ZXYAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
        "                             weight_decay=weight_decay, grad_clip=grad_clip, \n",
        "                             opt_func=opt_func)"
      ],
      "metadata": {
        "id": "-qCzwKr9Xcl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfc59835-7f91-4eac-cac4-72ff57c8b174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-e74db46226ba>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(torch.sum(preds == labels))/len(preds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00040, train_loss: 4.0654, val_loss: 4.1481, val_acc: 0.0938\n",
            "Epoch [1], last_lr: 0.00040, train_loss: 4.1172, val_loss: 4.2926, val_acc: 0.0938\n",
            "Epoch [2], last_lr: 0.00040, train_loss: 4.0822, val_loss: 4.0998, val_acc: 0.1328\n",
            "Epoch [3], last_lr: 0.00040, train_loss: 4.0416, val_loss: 4.2711, val_acc: 0.1328\n",
            "Epoch [4], last_lr: 0.00040, train_loss: 4.0604, val_loss: 4.2929, val_acc: 0.0938\n",
            "Epoch [5], last_lr: 0.00040, train_loss: 4.0117, val_loss: 4.0907, val_acc: 0.0911\n",
            "Epoch [6], last_lr: 0.00040, train_loss: 4.1280, val_loss: 3.9680, val_acc: 0.1328\n",
            "Epoch [7], last_lr: 0.00040, train_loss: 4.1001, val_loss: 4.0276, val_acc: 0.0938\n",
            "Epoch [8], last_lr: 0.00040, train_loss: 4.0889, val_loss: 5.0971, val_acc: 0.0938\n",
            "Epoch [9], last_lr: 0.00040, train_loss: 4.1073, val_loss: 4.2049, val_acc: 0.0938\n",
            "Epoch [10], last_lr: 0.00040, train_loss: 4.0809, val_loss: 4.1776, val_acc: 0.1328\n",
            "Epoch [11], last_lr: 0.00040, train_loss: 4.1064, val_loss: 4.3510, val_acc: 0.1354\n",
            "Epoch [12], last_lr: 0.00040, train_loss: 4.1006, val_loss: 3.8289, val_acc: 0.1745\n",
            "Epoch [13], last_lr: 0.00040, train_loss: 4.0558, val_loss: 4.0099, val_acc: 0.1328\n",
            "Epoch [14], last_lr: 0.00040, train_loss: 4.0981, val_loss: 4.6815, val_acc: 0.0911\n",
            "Epoch [15], last_lr: 0.00040, train_loss: 4.0870, val_loss: 4.1988, val_acc: 0.0938\n",
            "Epoch [16], last_lr: 0.00040, train_loss: 4.0761, val_loss: 4.1471, val_acc: 0.0938\n",
            "Epoch [17], last_lr: 0.00040, train_loss: 4.0681, val_loss: 4.3330, val_acc: 0.0911\n",
            "Epoch [18], last_lr: 0.00040, train_loss: 4.1204, val_loss: 4.3833, val_acc: 0.0938\n",
            "Epoch [19], last_lr: 0.00040, train_loss: 4.1004, val_loss: 4.3733, val_acc: 0.0964\n",
            "Epoch [20], last_lr: 0.00040, train_loss: 4.0909, val_loss: 4.1292, val_acc: 0.0964\n",
            "Epoch [21], last_lr: 0.00040, train_loss: 4.0670, val_loss: 4.2376, val_acc: 0.0938\n",
            "Epoch [22], last_lr: 0.00040, train_loss: 4.0716, val_loss: 3.9704, val_acc: 0.1745\n",
            "Epoch [23], last_lr: 0.00040, train_loss: 4.0655, val_loss: 4.2295, val_acc: 0.1328\n",
            "Epoch [24], last_lr: 0.00040, train_loss: 4.1076, val_loss: 4.3077, val_acc: 0.0911\n",
            "Epoch [25], last_lr: 0.00040, train_loss: 4.0768, val_loss: 4.1472, val_acc: 0.1328\n",
            "Epoch [26], last_lr: 0.00040, train_loss: 4.0746, val_loss: 4.2718, val_acc: 0.1328\n",
            "Epoch [27], last_lr: 0.00040, train_loss: 4.1029, val_loss: 4.3346, val_acc: 0.0938\n",
            "Epoch [28], last_lr: 0.00040, train_loss: 4.0933, val_loss: 4.2214, val_acc: 0.0938\n",
            "Epoch [29], last_lr: 0.00040, train_loss: 4.1063, val_loss: 4.4152, val_acc: 0.0938\n",
            "Epoch [30], last_lr: 0.00040, train_loss: 4.0859, val_loss: 3.9638, val_acc: 0.0911\n",
            "Epoch [31], last_lr: 0.00040, train_loss: 4.0969, val_loss: 3.9736, val_acc: 0.1328\n",
            "Epoch [32], last_lr: 0.00040, train_loss: 4.1254, val_loss: 3.9721, val_acc: 0.1302\n",
            "Epoch [33], last_lr: 0.00040, train_loss: 4.0807, val_loss: 4.4539, val_acc: 0.0938\n",
            "Epoch [34], last_lr: 0.00040, train_loss: 4.1032, val_loss: 4.1647, val_acc: 0.1328\n",
            "Epoch [35], last_lr: 0.00040, train_loss: 4.1402, val_loss: 4.2140, val_acc: 0.0938\n",
            "Epoch [36], last_lr: 0.00040, train_loss: 4.0583, val_loss: 4.3706, val_acc: 0.0938\n",
            "Epoch [37], last_lr: 0.00040, train_loss: 4.1309, val_loss: 4.0643, val_acc: 0.1354\n",
            "Epoch [38], last_lr: 0.00040, train_loss: 4.0922, val_loss: 4.3842, val_acc: 0.1328\n",
            "Epoch [39], last_lr: 0.00040, train_loss: 4.0963, val_loss: 4.4588, val_acc: 0.1328\n",
            "Epoch [40], last_lr: 0.00040, train_loss: 4.0899, val_loss: 4.0023, val_acc: 0.1719\n",
            "Epoch [41], last_lr: 0.00040, train_loss: 4.1145, val_loss: 4.1954, val_acc: 0.0938\n",
            "Epoch [42], last_lr: 0.00040, train_loss: 4.0899, val_loss: 3.8079, val_acc: 0.1302\n",
            "Epoch [43], last_lr: 0.00040, train_loss: 4.0805, val_loss: 3.9242, val_acc: 0.0938\n",
            "Epoch [44], last_lr: 0.00040, train_loss: 4.0911, val_loss: 4.1169, val_acc: 0.0938\n",
            "Epoch [45], last_lr: 0.00040, train_loss: 4.0968, val_loss: 3.9378, val_acc: 0.0938\n",
            "Epoch [46], last_lr: 0.00040, train_loss: 4.0991, val_loss: 4.0333, val_acc: 0.1328\n",
            "Epoch [47], last_lr: 0.00040, train_loss: 4.1163, val_loss: 3.9685, val_acc: 0.1693\n",
            "Epoch [48], last_lr: 0.00040, train_loss: 4.1234, val_loss: 4.3091, val_acc: 0.0938\n",
            "Epoch [49], last_lr: 0.00040, train_loss: 4.0686, val_loss: 4.1049, val_acc: 0.0911\n",
            "Epoch [50], last_lr: 0.00040, train_loss: 4.0969, val_loss: 4.0805, val_acc: 0.1719\n",
            "Epoch [51], last_lr: 0.00040, train_loss: 4.0890, val_loss: 4.4524, val_acc: 0.0938\n",
            "Epoch [52], last_lr: 0.00040, train_loss: 4.0469, val_loss: 3.8412, val_acc: 0.1328\n",
            "Epoch [53], last_lr: 0.00040, train_loss: 4.1018, val_loss: 3.9700, val_acc: 0.0885\n",
            "Epoch [54], last_lr: 0.00040, train_loss: 4.0511, val_loss: 4.0124, val_acc: 0.1328\n",
            "Epoch [55], last_lr: 0.00040, train_loss: 4.1134, val_loss: 4.0372, val_acc: 0.1328\n",
            "Epoch [56], last_lr: 0.00040, train_loss: 4.0415, val_loss: 4.2021, val_acc: 0.1719\n",
            "Epoch [57], last_lr: 0.00040, train_loss: 4.0756, val_loss: 4.1508, val_acc: 0.1328\n",
            "Epoch [58], last_lr: 0.00040, train_loss: 4.1547, val_loss: 4.2845, val_acc: 0.1328\n",
            "Epoch [59], last_lr: 0.00040, train_loss: 4.0987, val_loss: 4.3808, val_acc: 0.1354\n",
            "Epoch [60], last_lr: 0.00040, train_loss: 4.0467, val_loss: 4.1813, val_acc: 0.1328\n",
            "Epoch [61], last_lr: 0.00040, train_loss: 4.0650, val_loss: 4.2264, val_acc: 0.0938\n",
            "Epoch [62], last_lr: 0.00040, train_loss: 4.0775, val_loss: 3.8547, val_acc: 0.1328\n",
            "Epoch [63], last_lr: 0.00040, train_loss: 4.0766, val_loss: 4.3478, val_acc: 0.0938\n",
            "Epoch [64], last_lr: 0.00040, train_loss: 4.0575, val_loss: 4.0799, val_acc: 0.1302\n",
            "Epoch [65], last_lr: 0.00040, train_loss: 4.0764, val_loss: 4.1635, val_acc: 0.0938\n",
            "Epoch [66], last_lr: 0.00040, train_loss: 4.1094, val_loss: 3.9772, val_acc: 0.1328\n",
            "Epoch [67], last_lr: 0.00040, train_loss: 4.0634, val_loss: 4.1738, val_acc: 0.1328\n",
            "Epoch [68], last_lr: 0.00040, train_loss: 4.1068, val_loss: 4.3729, val_acc: 0.0911\n",
            "Epoch [69], last_lr: 0.00040, train_loss: 4.0272, val_loss: 4.1291, val_acc: 0.0938\n",
            "Epoch [70], last_lr: 0.00040, train_loss: 4.0750, val_loss: 4.3566, val_acc: 0.0938\n",
            "Epoch [71], last_lr: 0.00040, train_loss: 4.0724, val_loss: 4.5036, val_acc: 0.0938\n",
            "Epoch [72], last_lr: 0.00040, train_loss: 4.1052, val_loss: 4.2742, val_acc: 0.0938\n",
            "Epoch [73], last_lr: 0.00040, train_loss: 4.0895, val_loss: 4.5359, val_acc: 0.0938\n",
            "Epoch [74], last_lr: 0.00040, train_loss: 4.0751, val_loss: 4.0327, val_acc: 0.0938\n",
            "Epoch [75], last_lr: 0.00040, train_loss: 4.0968, val_loss: 3.7839, val_acc: 0.2109\n",
            "Epoch [76], last_lr: 0.00040, train_loss: 4.1227, val_loss: 4.3701, val_acc: 0.0964\n",
            "Epoch [77], last_lr: 0.00040, train_loss: 4.0414, val_loss: 4.0479, val_acc: 0.1328\n",
            "Epoch [78], last_lr: 0.00040, train_loss: 4.0728, val_loss: 4.1687, val_acc: 0.0964\n",
            "Epoch [79], last_lr: 0.00040, train_loss: 4.0847, val_loss: 4.4040, val_acc: 0.0911\n",
            "Epoch [80], last_lr: 0.00040, train_loss: 4.1302, val_loss: 4.3685, val_acc: 0.0911\n",
            "Epoch [81], last_lr: 0.00040, train_loss: 4.1093, val_loss: 4.3363, val_acc: 0.0938\n",
            "Epoch [82], last_lr: 0.00040, train_loss: 4.0389, val_loss: 4.2774, val_acc: 0.0938\n",
            "Epoch [83], last_lr: 0.00040, train_loss: 4.0559, val_loss: 4.4191, val_acc: 0.0964\n",
            "Epoch [84], last_lr: 0.00040, train_loss: 4.0661, val_loss: 4.1490, val_acc: 0.1302\n",
            "Epoch [85], last_lr: 0.00040, train_loss: 4.1033, val_loss: 3.9886, val_acc: 0.0938\n",
            "Epoch [86], last_lr: 0.00040, train_loss: 4.0865, val_loss: 4.8483, val_acc: 0.0938\n",
            "Epoch [87], last_lr: 0.00040, train_loss: 4.0821, val_loss: 4.1742, val_acc: 0.1328\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8a45cfb68293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              opt_func=opt_func)\n",
            "\u001b[0;32m<ipython-input-27-b26ba26092cb>\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(epochs, max_lr, model, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-62a2be3a8bd2>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"\"\"Yield a batch of data after moving it to device\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAIopOSZY2Vt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}